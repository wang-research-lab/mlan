dataset_path: lmms-lab/POPE
test_split: test
group: pope
task: pope_llava_cot
output_type: generate_until
fewshot_delimiter: "</s>"
doc_to_text: !function helper.prompt_llava_cot
doc_to_visual: !function helper.aokvqa_doc_to_visual
doc_to_target: !function helper.prepare_gt
generation_kwargs:
  max_length: 2048 #No limit
  do_sample: false
process_results: !function helper.pope_process_results
metric_list:
  - metric: exact_match
    aggregation: mean
    higher_is_better: true
    ignore_case: true
    ignore_punctuation: true
  - metric: pope_accuracy
    aggregation: !function helper.pope_aggregate_accuracy
    higher_is_better: true
  - metric: pope_precision
    aggregation: !function helper.pope_aggregate_precision
    higher_is_better: true
  - metric: pope_recall
    aggregation: !function helper.pope_aggregate_recall
    higher_is_better: true
  - metric: pope_f1_score
    aggregation: !function helper.pope_aggregate_f1_score
    higher_is_better: true
  - metric: pope_yes_ratio
    aggregation: !function helper.pope_aggregate_yes_ratio
    higher_is_better: true
filter_list:
  - name: "extract_answer"
    filter: 
      - function: "regex"
        regex_pattern: 'answer is: (.+?)\.'
      - function: "true_false"
      - function: "take_first"
model_specific_prompt_kwargs:
  default:
    pre_prompt: ""
    post_prompt: ""
metadata:
  version: 1.0