{
  "os":  "Linux-5.10.226-1.el8.x86_64-x86_64-with-glibc2.28",
  "python":  "3.10.15",
  "startedAt":  "2024-11-04T22:40:42.485112Z",
  "args":  [
    "--local_rank=0",
    "--deepspeed",
    "/ib-scratch/chenguang02/t.tovi/code/MLAN/scripts/config/zero2.json",
    "--model_name_or_path",
    "meta-llama/Llama-2-7b-hf",
    "--version",
    "plain",
    "--data_path",
    "/ib-scratch/chenguang03/vision_share//datasets/llava/blip_laion_cc_sbu_558k.json",
    "--image_folder",
    "/ib-scratch/chenguang03/vision_share//datasets/llava/images",
    "--vision_tower",
    "openai/clip-vit-large-patch14-336",
    "--mm_projector_type",
    "mlp2x_gelu",
    "--freeze_backbone",
    "True",
    "--freeze_vision_tower",
    "True",
    "--freeze_mm_mlp_adapter",
    "False",
    "--mm_vision_select_layer",
    "-2",
    "--mm_use_im_start_end",
    "False",
    "--mm_use_im_patch_token",
    "False",
    "--bf16",
    "True",
    "--output_dir",
    "/ib-scratch/chenguang03/vision_share//models/llava-llama2-7b-pretrain",
    "--num_train_epochs",
    "1",
    "--per_device_train_batch_size",
    "32",
    "--per_device_eval_batch_size",
    "4",
    "--gradient_accumulation_steps",
    "1",
    "--evaluation_strategy",
    "no",
    "--save_strategy",
    "steps",
    "--save_steps",
    "24000",
    "--save_total_limit",
    "1",
    "--learning_rate",
    "1e-3",
    "--weight_decay",
    "0.",
    "--warmup_ratio",
    "0.03",
    "--lr_scheduler_type",
    "cosine",
    "--logging_steps",
    "1",
    "--tf32",
    "True",
    "--model_max_length",
    "2048",
    "--gradient_checkpointing",
    "True",
    "--dataloader_num_workers",
    "4",
    "--lazy_preprocess",
    "True",
    "--report_to",
    "wandb"
  ],
  "program":  "/ib-scratch/chenguang02/t.tovi/code/MLAN/llava/train/train_mem.py",
  "codePath":  "llava/train/train_mem.py",
  "git":  {
    "remote":  "https://github.com/ToviTu/MLAN.git",
    "commit":  "14dfc7e5c5842fcedfd797f36cc8f3c8b2495a53"
  },
  "email":  "jianhong.t@wustl.edu",
  "root":  "/ib-scratch/chenguang02/t.tovi/code/MLAN",
  "host":  "chenguang02.engr.wustl.edu",
  "username":  "jianhong.t",
  "executable":  "/scratch/t.tovi/packages/test/bin/python",
  "codePathLocal":  "llava/train/train_mem.py",
  "cpu_count":  128,
  "cpu_count_logical":  128,
  "gpu":  "NVIDIA RTX A6000",
  "gpu_count":  8,
  "disk":  {
    "/":  {
      "total":  "68684877824",
      "used":  "23702032384"
    }
  },
  "memory":  {
    "total":  "540859650048"
  },
  "cpu":  {
    "count":  128,
    "countLogical":  128
  },
  "gpu_nvidia":  [
    {
      "name":  "NVIDIA RTX A6000",
      "memoryTotal":  "51527024640",
      "cudaCores":  10752,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA RTX A6000",
      "memoryTotal":  "51527024640",
      "cudaCores":  10752,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA RTX A6000",
      "memoryTotal":  "51527024640",
      "cudaCores":  10752,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA RTX A6000",
      "memoryTotal":  "51527024640",
      "cudaCores":  10752,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA RTX A6000",
      "memoryTotal":  "51527024640",
      "cudaCores":  10752,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA RTX A6000",
      "memoryTotal":  "51527024640",
      "cudaCores":  10752,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA RTX A6000",
      "memoryTotal":  "51527024640",
      "cudaCores":  10752,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA RTX A6000",
      "memoryTotal":  "51527024640",
      "cudaCores":  10752,
      "architecture":  "Ampere"
    }
  ],
  "cudaVersion":  "12.6"
}